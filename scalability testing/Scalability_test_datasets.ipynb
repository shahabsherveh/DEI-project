{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6523e282-9a0a-4d48-9c2a-c3f7ec9eebcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import pyspark\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8453689-ee97-49ad-ac4a-1a787a38fb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting random seed for notebook reproducability\n",
    "rnd_seed=23\n",
    "np.random.seed=rnd_seed\n",
    "np.random.set_state=rnd_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "275acd83-d607-4ab3-a591-2efd9d444709",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/19 07:55:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark_session = SparkSession.builder \\\n",
    "        .master(\"spark://192.168.2.46:7077\") \\\n",
    "        .appName(\"Scalability_B\") \\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", False) \\\n",
    "        .config(\"spark.dynamicAllocation.shuffleTracking.enabled\", True) \\\n",
    "        .config(\"spark.shuffle.service.enabled\", False) \\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\", \"30s\") \\\n",
    "        .config(\"spark.dynamicAllocation.minExecutors\", 1) \\\n",
    "        .config(\"spark.dynamicAllocation.maxExecutors\", 10) \\\n",
    "        .config(\"spark.executor.cores\", 4) \\\n",
    "        .config(\"spark.executor.memory\", \"4G\") \\\n",
    "        .config(\"spark.driver.memory\", \"2G\") \\\n",
    "        .config(\"spark.driver.port\", 9999) \\\n",
    "        .config(\"spark.blockManager.port\", 10005) \\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark_context = spark_session.sparkContext\n",
    "spark_context.setLogLevel(\"ERROR\")\n",
    "\n",
    "spark_context = spark_session.sparkContext\n",
    "spark_context.setLogLevel(\"ERROR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1741fcec-a24a-487b-973c-cc11c15b20ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/pyspark/sql/context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sqlContext = SQLContext(spark_session.sparkContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "715b6e87-be65-46bc-acca-b80b5ff68259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:=====================================================>(146 + 1) / 147]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% : Execution Time = 335.01 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "df = sqlContext.read.json(\"hdfs://192.168.2.46:9000/data/corpus-webis-tldr-17.json\").sample(fraction=0.1, seed=42)    \n",
    "end_time = time.time()\n",
    "print(f\"10% : Execution Time = {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b273f7d0-1a61-4b07-ab62-67f43d7286d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+-----------+-------+--------------------+-------------------+------------+--------------------+-----------+-----+\n",
      "|             author|                body|             content|content_len|     id|      normalizedBody|          subreddit|subreddit_id|             summary|summary_len|title|\n",
      "+-------------------+--------------------+--------------------+-----------+-------+--------------------+-------------------+------------+--------------------+-----------+-----+\n",
      "|           chrom_ed|So you're saying ...|So you're saying ...|        134|c6agxtv|So you're saying ...|              apple|    t5_2qh1f|you don't seem to...|          9| NULL|\n",
      "|        fallsuspect|You probably won'...|You probably won'...|         79|c6bncqn|You probably won'...|          AskReddit|    t5_2qh1i|just get both of ...|         11| NULL|\n",
      "|     Buck_Speedjunk|This picture does...|This picture does...|         18|c6c4uks|This picture does...|              trees|    t5_2r9vp|It's a half-assed...|         13| NULL|\n",
      "|    dannywarbucks11|My then 10 month ...|My then 10 month ...|        142|c6e3891|My then 10 month ...|          AskReddit|    t5_2qh1i|My 10 month old m...|         10| NULL|\n",
      "|gloriously_offtopic|This reminds me o...|This reminds me o...|        506|c6effzd|This reminds me o...|                WTF|    t5_2qh61|Naked game of twi...|          6| NULL|\n",
      "|           Omniduro|Clearly I'm open ...|Clearly I'm open ...|         23|c6ery44|Clearly I'm open ...|fffffffuuuuuuuuuuuu|    t5_2qqlo|i'm bi. Moving ri...|          5| NULL|\n",
      "|              M_Bus|Have you ever rea...|Have you ever rea...|        762|c6evqgb|Have you ever rea...|      TrueAskReddit|    t5_2s91q|Both may be attem...|         21| NULL|\n",
      "|    iceman_in_black|I (a guy) was tal...|I (a guy) was tal...|        180|c6fimgo|I (a guy) was tal...|          AskReddit|    t5_2qh1i|I'm sure it's ext...|         26| NULL|\n",
      "|        takinitslow|does anyone know ...|does anyone know ...|         41|c6gcfyn|does anyone know ...|          festivals|    t5_2re9k|         CP was sick|          3| NULL|\n",
      "|              bowdo|I did this exact ...|I did this exact ...|        174|c6hrm48|I did this exact ...|         technology|    t5_2qh16|scammer calls bac...|         10| NULL|\n",
      "+-------------------+--------------------+--------------------+-----------+-------+--------------------+-------------------+------------+--------------------+-----------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c57c7f77-3c24-422a-88e7-beb3b9b1ee80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:=====================================================>(146 + 1) / 147]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25% : Execution Time = 151.84 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#df_25 = sqlContext.read.json(\"hdfs://192.168.2.46:9000/data/corpus-webis-tldr-17.json\").sample(fraction=0.25, seed=42)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df_25 = sqlContext.read.json(\"hdfs://192.168.2.46:9000/data/corpus-webis-tldr-17.json\").sample(fraction=0.25, seed=42)    \n",
    "end_time = time.time()\n",
    "print(f\"25% : Execution Time = {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20b242a1-b8cd-470e-b739-c0c29e725d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 21:=====================================================>(146 + 1) / 147]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5% : Execution Time = 172.34 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#df_5 = sqlContext.read.json(\"hdfs://192.168.2.46:9000/data/corpus-webis-tldr-17.json\").sample(fraction=0.5, seed=42)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df_5 = sqlContext.read.json(\"hdfs://192.168.2.46:9000/data/corpus-webis-tldr-17.json\").sample(fraction=0.5, seed=42)    \n",
    "end_time = time.time()\n",
    "print(f\"5% : Execution Time = {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65b786e7-d4dc-43ce-b08a-4429d28e1dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:=====================================================>(146 + 1) / 147]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75% : Execution Time = 178.96 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#df_75 = sqlContext.read.json(\"hdfs://192.168.2.46:9000/data/corpus-webis-tldr-17.json\").sample(fraction=0.75, seed=42)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df_75 = sqlContext.read.json(\"hdfs://192.168.2.46:9000/data/corpus-webis-tldr-17.json\").sample(fraction=0.75, seed=42)    \n",
    "end_time = time.time()\n",
    "print(f\"75% : Execution Time = {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d04104e-1dfb-468c-a4ce-60afe0dd8026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 23:=====================================================>(146 + 1) / 147]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% : Execution Time = 112.08 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#df_95 = sqlContext.read.json(\"hdfs://192.168.2.46:9000/data/corpus-webis-tldr-17.json\").sample(fraction=0.95, seed=42)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df_95 = sqlContext.read.json(\"hdfs://192.168.2.46:9000/data/corpus-webis-tldr-17.json\").sample(fraction=0.95, seed=42)    \n",
    "end_time = time.time()\n",
    "print(f\"95% : Execution Time = {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce7f3f3e-f095-415c-90f4-c857eed17d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:=====================================================>(146 + 1) / 147]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1% : Execution Time = 178.84 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#df_1 = sqlContext.read.json(\"hdfs://192.168.2.46:9000/data/corpus-webis-tldr-17.json\").sample(fraction=0.01, seed=42)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df_1 = sqlContext.read.json(\"hdfs://192.168.2.46:9000/data/corpus-webis-tldr-17.json\").sample(fraction=0.01, seed=42)    \n",
    "end_time = time.time()\n",
    "print(f\"1% : Execution Time = {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "230781b3-2046-453b-bb4e-69c1b96abde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% Dataset: Execution Time = 107.35 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75% Dataset: Execution Time = 97.86 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% Dataset: Execution Time = 99.05 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=====================================================>(146 + 1) / 147]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1% Dataset: Execution Time = 89.07 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def test_scalability(df, label):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Example transformation and action\n",
    "    result = df.groupBy(\"content_len\").count().collect()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"{label}: Execution Time = {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Run tests\n",
    "test_scalability(df, \"10% Dataset\")\n",
    "test_scalability(df_75, \"75% Dataset\")\n",
    "test_scalability(df_95, \"95% Dataset\")\n",
    "test_scalability(df_1, \"1% Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "efc6ea93-d660-437e-96b7-1081ff33dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
