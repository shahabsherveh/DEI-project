{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a35b78d1-986e-4653-a28c-89ae7d3a84b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Spark NLP Session Started\n",
      " Loading Reddit JSON data from HDFS...\n",
      " Loading bot list from CSV...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ubuntu/botlist.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m botlist_csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ubuntu/botlist.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Run preprocessing and bot filtering\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m df_cleaned \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_and_filter_bots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreddit_json_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbotlist_csv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Show the first few cleaned rows\u001b[39;00m\n\u001b[1;32m     33\u001b[0m df_cleaned\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormalizedBody\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m10\u001b[39m, truncate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/DEI-project/preprocessing/preprocessing files/preprocessing_func.py:24\u001b[0m, in \u001b[0;36mpreprocess_and_filter_bots\u001b[0;34m(spark_context, reddit_json_path, botlist_csv_path)\u001b[0m\n\u001b[1;32m     21\u001b[0m df \u001b[38;5;241m=\u001b[39m spark_context\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mjson(reddit_json_path)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Loading bot list from CSV...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m bot_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbotlist_csv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m bot_list \u001b[38;5;241m=\u001b[39m bot_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAAbot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39munique()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Loaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(bot_list)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m bot names.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ubuntu/botlist.csv'"
     ]
    }
   ],
   "source": [
    "#Example usage of the preprocess_and_filter_bots function \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import StringType\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import count\n",
    "from preprocessing_func import preprocess_and_filter_bots\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RedditSentimentAnalysis\") \\\n",
    "    .master(\"spark://192.168.2.46:7077\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", True) \\\n",
    "    .config(\"spark.shuffle.service.enabled\", False) \\\n",
    "    .config(\"spark.dynamicAllocation.executorIdleTimeout\", \"30s\") \\\n",
    "    .config(\"spark.executor.cores\", 2) \\\n",
    "    .config(\"spark.cores.max\", 4) \\\n",
    "    .config(\"spark.driver.port\", 9999) \\\n",
    "    .config(\"spark.blockManager.port\", 10005) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"✅ Spark NLP Session Started\")\n",
    "\n",
    "# Define file paths\n",
    "reddit_json_path = \"hdfs://192.168.2.46:9000/data/corpus-webis-tldr-17.json\"\n",
    "botlist_csv_path = \"/home/ubuntu/botlist.csv\"\n",
    "\n",
    "# Run preprocessing and bot filtering\n",
    "df_cleaned = preprocess_and_filter_bots(spark, reddit_json_path, botlist_csv_path)\n",
    "\n",
    "# Show the first few cleaned rows\n",
    "df_cleaned.select(\"author\", \"normalizedBody\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34d4aa96-ec59-46bb-a683-c6c319844db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Spark NLP Session Started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample bot names: ['ADHDbot', 'ALTcointip', 'AVR_Modbot', 'A_random_gif', 'AltCodeBot', 'Antiracism_Bot', 'ApiContraption', 'AssHatBot', 'AtheismModBot', 'AutoInsult']\n",
      "Loaded 27 positive words and 27 negative words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
      "|author            |normalizedBody                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |sentiment|\n",
      "+------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
      "|raysofdarkmatter  |I think it should be fixed on either UTC standard or UTC+1 year around, with the current zone offsets. \\n Moving timescales add a lot of complexity to the implementation of timekeeping systems and have [dubious value]( \\n I think seasonal shifting time made sense in the pre-electric past, when timekeeping was more flexible and artificial light was inefficient and often dangerous. \\n Now we have machines that work easily with simple timekeeping rules, and it's more beneficial to spend a small amount on energy for lighting, and save the larger cost of engineering things to work with the complex timekeeping rules, as well as saving the irritation to humans. \\n Lighting has gotten much more efficient over time; we can squeeze out a lot more photons per unit of energy from a 2012 CFL or LED than a candle could in 1780, or a lightbulb could in 1950. \\n There's a lot of room for improvement in how we use lights as well; as lighting control gets more intelligent, there will be a lot of savings from not illuminating inactive spaces constantly. \\n tl;dr: Shifting seasonal time is no longer worth it. \\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |neutral  |\n",
      "|Stork13           |Art is about the hardest thing to categorize in terms of good and bad. To consider one work or artist as dominate over another comes down to personal opinion. Sure some things maybe blatantly better than other works, but it ultimately lies with the individual. I personally enjoy the work of \"street artists\" (using quotations not to be sarcastic, but mainly because this is in a different category than graffiti and since my background is not in art I don't know what the \"proper\" term is , if there is one), but I do see where you are coming from. CLET tends to use the same images continuously (to a point where one could say \"Is this it?\") as do most street artists (I do think this term is thrown around a lot more than it should be, I agree with you there) and it can be annoying. \\n tl;dr: Personal opinions 'n shit. \\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |positive |\n",
      "|Cloud_dreamer     |Ask me what I think about the Wall Street Journal and I'll tell you about it's bland, monumental, walls of text. \\n This isn't the deeply engrossing reading material that the bubblegum popping, paparazzi loving celebrities read in the daily publications of The L.A. Times. \\n It’s apparent that Wall Street journal is going after that greed driven, white GOP, 50-90-or-so demographic, with its over-the-top use of big words nobody really gives a shit about (eg. “gratuitous....magilla ”),  TL;DR insults and slack ass insight. \\n Wall Street Journal misses on enough counts that not only did i yawn with boredom, i fell asleep trying to read through this crap. \\n It may be the paper for you, but if your in the the market for a new read, i'd at least counsel you on reading the Washington Post instead, due out on stands anytime, or the Globe, which is slated for a weekly release. \\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |neutral  |\n",
      "|NightlyReaper     |In Mechwarrior Online, I have begun to use a mouse for the \"turret\" aspect of the torso twist/tilt and a Logitech G13 for other controls (  The G-13 has a little thumbstick that works well for WASD functions and has a little keyboard to cover all the other (limited) controls required for MWO.  For modern games, I guess that's as close to HOTAS as they want you to get.  For a better solution, I think that with a joystick emulating mouse inputs it would be passable, but as you said:  It's presently a sad day and you have to be able to edit XML files to modify joystick input triggers and it starts becoming an occupation rather than a gaming hobby.  In Mechwarrior 2, 3, & 4 I use the Steel Battalion controller and it is freaking awesome to have the three axes of torso twist, tilt, walking direction, plus a real throttle, plus real hat switches for views, plus pedals for extra speed, stopping power and jumpjet control.  Not to mention the 32 other buttons and the flip cover over the eject button.  Check this control map by Baron Von Pilsner ( and look at my original posts for links to my Fully Enclosed Mech Simulator on Mechwarrior Online's forums for details. \\n TL/DR: Yes, Joysticks in modern games have apparently become passe unless you are playing a flight sim and that sucks. \\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |neutral  |\n",
      "|NuffZetPand0ra    |You are talking about the Charsi imbue, right? Or a cube upgrade?\\nIf we are talking Charsi imbue, you can only imbue WHITE items. This includes superior, but they will not neccesarily be superior after imbuing (they get random base-modifications). Bloodfist and Gorefoot are both uniques (gold), and therefore not eligible for imbuing.\\nWhen you imbue, the item level matters (the item level is hidden). The item is the same level as the monster who dropped it. That means, that the higher level the monster who dropped it, the more stats is available on that item. It is important to note that an item doesn't neccesarily use all it's stat potential. This means that the same item dropped in a1 and a2 can has the possibility of some very different outcomes.\\nAfter the imbue, the item can be as good as if the monster itself had dropped a rare (yellow) item. Imbued weapons will always turn out as rare items.\\nTo answer your question, you should just progress like you are now, fighting the hardest monsters you can. When a potential good white item appears, try to imbue that. Class specifiq items has a better chance to give +skills to your class. Circlets has the higest bonuses regarding yellow items. And you can get an extra base stat advantage by using exceoptional (nightmare) items, which will drop in a4-5 from time to time. You can check out monster levels, and item qualities (normal, exceptional, elite) on arreat summit ofc. :) \\n EDIT (forgot infoz):\\nIn cases of imbue-eligible items with base bonuses (maces, wands, staffs and class specifique items, and any other item with +skills etc.) will loose their current bonuses due to the base item reroll. They can get extra skills from the base item AND the rarity class. Say, if you imbue a staff with +1 fireball, it will reroll that base staff. It might turn out with a staff with +1 icebolt and +1 warmth, and then you add the bonuses the rarity would give you, lets say +1 icebolt and +1 fireball. Then your +1 fireball staff will have turned into a +2 icebolt +1 fireball staff. It might as well turn into any other staff allowed by it's item lvl though. \\n As far as I recall, weapon damage and defense values are not rerolled. I am not 100% positive on this though. Haven't played d2 for a looong time :P \\n TLDR: Class only items dropped from high-lvl monsters. \\n|positive |\n",
      "|beatlecreedcabaret|All but one of my nails were in the ballpark of 1 1/8\" - 1 1/2\" long when my ring finger nail broke to the quick on Monday! It was the second break on the same hand in about a month, so I finally had to get compulsive and make all the nails the same length! I probably cut off more than half the length of the free edge. \\n As a side note, I used to be a  serious  nail biter all through my childhood and high school. I have had occasional relapses in my adulthood as well, but the point I'm trying to make is that my nail beds are  really  short, and I think my nails that short show about 1/8\" of my fingertips and look so sad! \\n TL;DR: OPI Nail Envy! \\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |neutral  |\n",
      "|nobodysdiary      |I could give a shit about turn by turn directions because I never drive and the new maps doesn't have ANY public transportation directions which is just complete bullshit -- especially for a company that is supposedly \"green\" conscious. \\n I know Apple and others have said that you can just get a 3rd party app, but to be honest I haven't found one for NYC Metro area that is as fast and complete as iOS5 Maps. It has integrated bus routes/schedules and train schedules and as someone else pointed out in another thread about this subject, you will need another 3rd party app if you go to a city other than your own, instead of easily being able to get directions as you travel. \\n I would also argue that since NYC of all places has a pretty shitty selection of 3rd party options, that the available options in other smaller major cities would be significantly shittier. \\n TL;DR  - I don't drive like  most  people in major cities, and need public transit directions integrated in iOS6 Maps. \\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |neutral  |\n",
      "|chrom_ed          |So you're saying \"try it, I might not mind losing access to directions that follow my only available mode of transportation (public)\"? This isn't a it might be ok but some people don't like it issue like Siri not listening to you  well . This is removing an entire function that I use all the time. It's not worth it and I won't be upgrading. Especially since they still haven't provided a feature that lets you roll anything back to a previous version (which just boggles my mind). If have to roll everything back using a backup of it turned out that, yes, I really can't find my way through the maze of subways, busses, and trains that make up the greater NY area with a combination of 3D flyovers, luck, and  magic . \\n Tl;dr you don't seem to understand what's going on here. \\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |neutral  |\n",
      "|gadzookfilms      |I love this idea and most definitely want to help. I have a few concerns though. My primary concern is that of financing. Making movies isn't free as we all know. It's fine to work on one or two volunteer projects for fun and to build interest and community but somewhere down the line it must be made sustainable. Otherwise the turnover rate of artists skyrockets. \\n My secondary concern is keeping this as open, transparent, and democratic as possible. Reddit's strength is in the hive, for better or worse, and I'd hate to relegate decisions to a few of us who happen to live in LA. From the get-go this needs to be a global initiative. So yeah, getting out of that SoCal bubble is key. \\n TL;DR - How we make money? How we involve everyone, yo? \\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |neutral  |\n",
      "|iamacannibal      |Theres an entire small town under the lake by my house. I'll try and get up there soon to take pictures. the lake should be pretty empty right now. Usually is at the end of summer and before rainy season. It's actually pretty close to Shaver lake. Lake Kaweah in CA. I don't remember the story well but they either made the lake or made it bigger and the town had to be moved. didnt take down the buildings and once in a while you can see them sticking up a bit out of the water. I think the area use to just be a river. a decent part of the Central Valley use to be a lake because of all of the rivers flowing in. Shaver might be from this too. blocking off the rivers to dry up the valley. Not sure though. \\n this is what it use to be. Tulare Lake. Biggest lake on the west side of the Mississippi river. Now the valley is dried up but has some of the best soil for crops in the world. \\n TL;DR: I'll try and get some similar shots from lake Kaweah next time I'm up there because there is an entire small town under the lake. \\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |neutral  |\n",
      "+------------------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Summary: {'positive': 1111835, 'negative': 505324, 'neutral': 1855185}\n",
      "✅ Sentiment analysis completed and saved to HDFS\n"
     ]
    }
   ],
   "source": [
    "#Example of Sentiment Anlyser \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import StringType\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"RedditSentimentAnalysis\") \\\n",
    "    .master(\"spark://192.168.2.46:7077\") \\\n",
    "    .config(\"spark.dynamicAllocation.enabled\", True) \\\n",
    "    .config(\"spark.shuffle.service.enabled\", False) \\\n",
    "    .config(\"spark.dynamicAllocation.executorIdleTimeout\", \"30s\") \\\n",
    "    .config(\"spark.executor.cores\", 2) \\\n",
    "    .config(\"spark.cores.max\", 4) \\\n",
    "    .config(\"spark.driver.port\", 9999) \\\n",
    "    .config(\"spark.blockManager.port\", 10005) \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"✅ Spark NLP Session Started\")\n",
    "\n",
    "# Load Reddit comments from HDFS\n",
    "df = spark.read.json(\"hdfs://192.168.2.46:9000/data/corpus-webis-tldr-17.json\")\n",
    "\n",
    "# Load bot list\n",
    "bot_df = pd.read_csv(\"/home/ubuntu/botlist.csv\")\n",
    "bot_list = bot_df[\"AAbot\"].dropna().unique().tolist()\n",
    "print(\"Sample bot names:\", bot_list[:10])  # Show the first 10 bot usernames\n",
    "\n",
    "# Remove bot-generated comments\n",
    "df_filtered = df.filter(~col(\"author\").isin(bot_list))\n",
    "\n",
    "# Load positive and negative words from CSV files\n",
    "def load_words_from_csv(filepath):\n",
    "    words = set()\n",
    "    with open(filepath, \"r\") as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip header\n",
    "        for row in reader:\n",
    "            if row:  # Ensure row is not empty\n",
    "                words.add(row[0].strip().lower())\n",
    "    return words\n",
    "\n",
    "# File paths for sentiment words\n",
    "positive_words_file = \"/home/ubuntu/positive_words.csv\"\n",
    "negative_words_file = \"/home/ubuntu/negative_words.csv\"\n",
    "\n",
    "# Load words\n",
    "positive_words = load_words_from_csv(positive_words_file)\n",
    "negative_words = load_words_from_csv(negative_words_file)\n",
    "\n",
    "print(f\"Loaded {len(positive_words)} positive words and {len(negative_words)} negative words.\")\n",
    "\n",
    "# Define sentiment analysis function\n",
    "def analyze_sentiment(text):\n",
    "    if not text:\n",
    "        return \"neutral\"\n",
    "    words = set(text.lower().split())\n",
    "    pos_count = len(words & positive_words)\n",
    "    neg_count = len(words & negative_words)\n",
    "    \n",
    "    if pos_count > neg_count:\n",
    "        return \"positive\"\n",
    "    elif neg_count > pos_count:\n",
    "        return \"negative\"\n",
    "    return \"neutral\"\n",
    "\n",
    "# Register UDF\n",
    "sentiment_udf = udf(analyze_sentiment, StringType())\n",
    "\n",
    "# Apply sentiment analysis\n",
    "df_result = df_filtered.withColumn(\"sentiment\", sentiment_udf(col(\"normalizedBody\")))\n",
    "\n",
    "# Show results\n",
    "df_result.select(\"author\", \"normalizedBody\", \"sentiment\").show(10, truncate=False)\n",
    "\n",
    "def count_sentiments(df):\n",
    "    \"\"\"\n",
    "    Function to count the number of positive, negative, and neutral sentiments in a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df (DataFrame): The Spark DataFrame containing the sentiment column.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary with counts of each sentiment category.\n",
    "    \"\"\"\n",
    "    sentiment_counts = df.groupBy(\"sentiment\").agg(count(\"*\").alias(\"count\")).collect()\n",
    "    \n",
    "    sentiment_dict = {\"positive\": 0, \"negative\": 0, \"neutral\": 0}\n",
    "    \n",
    "    for row in sentiment_counts:\n",
    "        sentiment_dict[row[\"sentiment\"]] = row[\"count\"]\n",
    "    \n",
    "    return sentiment_dict\n",
    "\n",
    "# Call function on the resulting DataFrame\n",
    "sentiment_summary = count_sentiments(df_result)\n",
    "\n",
    "# Print results\n",
    "print(\"Sentiment Summary:\", sentiment_summary)\n",
    "\n",
    "# Save results back to HDFS\n",
    "#df_result.write.mode(\"overwrite\").json(\"hdfs://192.168.2.46:9000/output/reddit_sentiment.json\")\n",
    "\n",
    "print(\"✅ Sentiment analysis completed and saved to HDFS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34326626-34c2-4698-99cd-19ec9b11d5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop Spark\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
